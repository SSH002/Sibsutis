1. Реализовать параллельный алгоритм умножения двух матриц, используя CUDA, глобальную память и двумерную индексацию нитей и блоков. Одна нить вычисляет один элемент
результирующей матрицы. Матрицы подаются в память GPU в одномерном массиве. Сравнить время работы параллельного алгоритма (+ время на пересылку данных) и время работы
последовательного алгоритма, выполлняющегося на CPU на матрицах размером 2048 x 2048.

2. Реализовать параллельный алгоритм умножения матриц из первого пункта с применением разделяемой памяти. Схема работы с разделяемой памятью: host memory -> "device global
memory" -> device shared memory -> синхронизация потоков в блоке, если требуется (функция __syncthreads()) -> вычисления -> device global memory -> host memory. Сравнить
время работы алгоритма с временем работы алгоритма из пункта 1 на матрицах размера 64 x 64.

3. Доработать алгоритм из пункта 2 для вычислений больших матриц. Сравнить время работы алгоритма с временем работы алгоритма из пункта 1 на матрицах размером 2048 x 2048.

Алгоритмы должны вычислять произведение матриц любых размеров, помещающихся в память. В параллельных алгоритмах при замерах времени учитывать пересылку данных на GPU.